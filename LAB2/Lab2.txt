
Action Number 6
===============

LAB02
10th value of lab1
serialno   hinc 	rooms
1403 	   30600     4

10th value of lab2
education_level   white  black american_indian_alaska_native  asian  hawaii_pacific_islander others
16  			  141336 8358  1726  						  17960  416                     2734


Action Number 8
===============

Compare	the	median	and	the	mean.
If mean is less than the median:
left skwed
If mean is greater than the median:
right skwed

Does min and max quartiles make sense to you
      hinc             rooms      
 Min.   :      4   Min.   :1.000  
 1st Qu.:  26000   1st Qu.:4.000  
 Median :  50300   Median :6.000  
 Mean   :  67152   Mean   :5.627  
 3rd Qu.:  84200   3rd Qu.:7.000  
 Max.   :1620560   Max.   :9.000 

hinc min,max :: 4,1620560 (lot of variance, looks like an outlier)
rooms min,max :: 1,9 
Its not very clear in the lab documentation on the description of hinc

How	do the values returned by the cor() function differ from the results obtained in lab?
        hinc     rooms
hinc  1.0000000 0.3820145
rooms 0.3820145 1.0000000
cor function gives the correlation value between two varibales.

Action Number 10
================


Question 2 : Experiment with r for the follwing types
typeof(x)
class(x)
attributes(x)
names(x)
dim(x)
> n <- 1  # scalar
> s <- "Columbus, Ohio"   # string 

> levels <- c("Worst", "Bad", "Mediocre", "Good", "Awesome")
> x  = levels
> typeof(x)
[1] "character"
> class(x)
[1] "character"
> attributes(x)
NULL
> names(x)
NULL
> dim(x)
NULL

> ratings <- c("Worst", "Worst", "Bad", "Bad", "Good", "Bad", "Bad") 
> x  = ratings
> typeof(x)
[1] "character"
> class(x)
[1] "character"
> attributes(x)
NULL
> names(x)
NULL
> dim(x)
NULL

> critics <- c("Siskel", "Ebert", "Rowen", "Martin")
> x  = critics
> typeof(x)
[1] "character"
> class(x)
[1] "character"
> attributes(x)
NULL
> names(x)
NULL
> dim(x)
NULL

> movies <- c("The Undefeated", "Snakes on a Plane", "Encino Man", "Casablanca")
> x  = movies
> typeof(x)
[1] "character"
> class(x)
[1] "character"
> attributes(x)
NULL
> names(x)
NULL
> dim(x)
NULL

> attendance <- c(15, 350,175, 400)
> x  = attendance
> typeof(x)
[1] "double"
> class(x)
[1] "numeric"
> attributes(x)
NULL
> names(x)
NULL
> dim(x)
NULL

> reviewers <- c("Siskel", "Siskel", "Ebert", "Ebert", "Rowan", "Martin", "Rowan")
> x  = reviewers
> typeof(x)
[1] "character"
> class(x)
[1] "character"
> attributes(x)
NULL
> names(x)
NULL
> dim(x)
NULL

Question 3) Which	ones	work	on	which	kind	of	data	types?
Answer: for vectors we can only find the typeOf() and class of the vecxtor

Question 4) Type	these	values	into	the	RStudio	command	panel.
Answer: given above

Question 5) Typing	all	these	commands	for	each	variable	is	tedious.	Alternatively,	we	will write a	function tellme that	takes	a	variable	as	an	argument	and	performs typeof, class, names and str on	that	variable.
Answer : 

tellme <- function(x){
  a1 =typeof(x)
  a2 = class(x)
  a3 = names(x)
  a4 = str(x)
  res = c(a1,a2,a3,a4)
  return(res)
}




======================= LAB3

> summary(ds$income)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
      4   26000   50300   67200   84200 1620000 
> range(ds$income)
[1]       4 1620560
> sd(ds$income)
[1] 68178
> var(ds$income)
[1] 4.65e+09


> summary(ds$rooms)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   1.00    4.00    6.00    5.63    7.00    9.00 
> range(ds$rooms)
[1] 1 9
> sd(ds$rooms)
[1] 1.99

1.
No it dosent as a min hose value cannot have max income

2.
> (m <- mean(ds$income, trim=0.10) )
[1] 55347
67200

3.
In comparison mean is lower if you remove top and bottom 10 percent 

4.
> quantile(ds$income, seq(from=0, to=1, length=11))
    0%    10%    20%    30%    40%    50%    60%    70%    80%    90%   100% 
 10000  18200  27000  35630  45000  54600  66000  79500  98400 135000 910000 

 The generic function quantile produces sample quantiles corresponding to the given probabilities. The smallest observation corresponds to a probability of 0 and the largest to a probability of 1.

 5.
 They vary as the the cummulative value of income is given for percentage in steps of 10 after removing the edges.

 6.
 Yes they make more sence as we can see the distribution of income

 7.
 dataframe ds as its outliers are removed

1.
 head(ds)
  income rooms   wealth
1 105530     6  Wealthy
2 141500     8  Wealthy
3 161400     6  Wealthy
4  72600     5 UpperMid
5  61000     5 UpperMid
6  92000     6  Wealthy
> ?cut

2.
Dosent make sence as its plotiing only the fist 2 columns we need to transpose to make sence of it

ANOVA
5.
> summary(model)

Call:
lm(formula = log10(purchase_amt) ~ as.factor(offers), data = offertest)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.2426 -0.2867 -0.0314  0.3281  1.3010 

Coefficients:
                        Estimate Std. Error t value Pr(>|t|)    
(Intercept)               1.3401     0.0345   38.85  < 2e-16 ***
as.factor(offers)offer1   0.4360     0.0481    9.07  < 2e-16 ***
as.factor(offers)offer2   0.4162     0.0494    8.43  3.8e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 

Residual standard error: 0.444 on 497 degrees of freedom
Multiple R-squared: 0.171,	Adjusted R-squared: 0.167 
F-statistic: 51.2 on 2 and 497 DF,  p-value: <2e-16 

6.
2.
F score
51.2 and p-value: <2e-16

Yes since p valuse is less than 0%

3.
2e-16
3.8e-16

4. 
Yes we can reject the Ho as the p values are significant


> TukeyHSD(aov(model))
  Tukey multiple comparisons of means
    95% family-wise confidence level

Fit: aov(formula = model)

$`as.factor(offers)`
                 diff    lwr    upr p adj
offer1-noffer  0.4360  0.323 0.5490 0.000
offer2-noffer  0.4162  0.300 0.5323 0.000
offer2-offer1 -0.0198 -0.134 0.0947 0.913

6.1
No

6.2
offer2-offer1 has a an intercept that changes a lot

6.3. Which style of graph do you find more helpful?
Both are important as overlapping 

> mx - my
[1] -1.64
> pooled.var(x,y)
[1] 0.137

> tstat = (mean(x) - mean(y))/sqrt(pooled.var(x,y))
> tstat
[1] -4.43




